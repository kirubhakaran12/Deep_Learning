{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1701,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "size = 100\n",
    "x11 = np.random.uniform(low=0.0,high=1.0,size=size)\n",
    "x12 = np.random.uniform(low=2.0,high=8.0,size=size)\n",
    "x13 = np.random.uniform(low=6.0,high=8.0,size=size)\n",
    "\n",
    "x21 = np.random.uniform(low=10.0,high=11.0,size=size)\n",
    "x22 = np.random.uniform(low=12.0,high=18.0,size=size)\n",
    "x23 = np.random.uniform(low=16.0,high=18.0,size=size)\n",
    "\n",
    "#x31 = np.random.uniform(low=20.0,high=21.0,size=size)\n",
    "#x32 = np.random.uniform(low=22.0,high=28.0,size=size)\n",
    "#x33 = np.random.uniform(low=26.0,high=28.0,size=size)\n",
    "\n",
    "y1 = np.transpose(np.zeros(size))\n",
    "y2 = np.transpose(np.ones(size))\n",
    "#y3 = np.transpose(np.ones(size) * 2)\n",
    "\n",
    "X1 = np.transpose(np.array([x11, x12, x13]))\n",
    "X2 = np.transpose(np.array([x21, x22, x23]))\n",
    "#X3 = np.transpose(np.array([x31, x32, x33]))\n",
    "X = np.vstack((X1, X2))\n",
    "\n",
    "y = np.hstack((y1, y2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1703,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden_units = [3,3]\n",
    "#no_hidden = len(hidden_units)\n",
    "\n",
    "def weight_init(X, y, hidden_units):\n",
    "    \n",
    "    Weights = {}\n",
    "    Bias = {}\n",
    "    no_hidden = len(hidden_units)\n",
    "    no_features = X.shape[1]\n",
    "    for n, units in enumerate(hidden_units):\n",
    "        Weights['layer_{}'.format(n+1)] = np.random.rand(no_features,units) \n",
    "        Bias['layer_{}'.format(n+1)] = np.random.rand(units) \n",
    "        no_features = units\n",
    "    \n",
    "    labels = len(np.unique(y))\n",
    "    Weights['layer_{}'.format(no_hidden+1)] = np.random.rand(no_features, labels)\n",
    "    Bias['layer_{}'.format(no_hidden+1)] = np.random.rand(labels)\n",
    "    \n",
    "    return Weights, Bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1704,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inp):\n",
    "    return (1/(1 + np.exp(-inp)))\n",
    "\n",
    "def tanh(inp):\n",
    "    return (np.exp(inp) - np.exp(-inp))/(np.exp(inp) + np.exp(-inp))\n",
    "\n",
    "def relu(inp):\n",
    "    return np.maximum(inp,0)\n",
    "\n",
    "def softmax(inp):\n",
    "    op_exp = np.exp(inp)\n",
    "    return op_exp/op_exp.sum(axis = 1)[:,None]\n",
    "\n",
    "activation_fn = {'sigmoid': sigmoid, 'tanh': tanh, 'relu': relu}\n",
    "\n",
    "def gradient_sigmoid(inp):\n",
    "    return sigmoid(inp) * (1 - sigmoid(inp))\n",
    "\n",
    "def gradient_tanh(inp):\n",
    "    return (1 -tanh(inp)) * (1 + tanh(inp))\n",
    "\n",
    "def gradient_relu(inp):\n",
    "    inp[inp>0] = 1\n",
    "    inp[inp<0] = 0\n",
    "    return inp\n",
    "\n",
    "gradient_fn = {'sigmoid': gradient_sigmoid, 'tanh': gradient_tanh, 'relu': gradient_relu}\n",
    "\n",
    "def output_label_hot_encode(inp):\n",
    "    inp = inp.astype(int)\n",
    "    classes = np.unique(inp)\n",
    "    no_classes = classes.shape[0]\n",
    "    no_dim = inp.shape[0]\n",
    "    zero_arr = np.zeros((no_dim, no_classes))\n",
    "    zero_arr[np.arange(no_dim), inp] = 1.0\n",
    "    return zero_arr\n",
    "\n",
    "def cross_entropy_error(y_act, y_hat):\n",
    "    return np.sum(np.multiply(y_act, np.log(y_hat)) * -1)\n",
    "\n",
    "#def accuracy(y_hat, y_act):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, y, Weights, Bias, no_hidden, activation):\n",
    "    \n",
    "    layers = {}\n",
    "    layers['layer_{}'.format(0)] = X #input layer\n",
    "\n",
    "    for l in range(no_hidden):\n",
    "        layers['layer_wx_{}'.format(l+1)] = np.matmul(layers['layer_{}'.format(l)], Weights['layer_{}'.format(l+1)]) + Bias['layer_{}'.format(l+1)]\n",
    "        layers['layer_{}'.format(l+1)] = activation_fn[activation](layers['layer_wx_{}'.format(l+1)])\n",
    "        \n",
    "    layers['layer_wx_{}'.format(no_hidden+1)] = np.matmul(layers['layer_{}'.format(no_hidden)], Weights['layer_{}'.format(no_hidden+1)])\n",
    "    layers['layer_{}'.format(no_hidden+1)] = softmax(layers['layer_wx_{}'.format(no_hidden+1)])\n",
    "    \n",
    "    y_hat = layers['layer_{}'.format(no_hidden+1)]\n",
    "        \n",
    "    return (layers, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1706,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(layers, y_act, y_hat, Weights, Bias, no_hidden, activation):\n",
    "    \n",
    "    gradients = {}\n",
    "    dim = y_act.shape[0]\n",
    "    \n",
    "    gradients['dL/dA_layer_{}'.format(no_hidden+1)]  = ((y_act - y_hat) * -1)/dim\n",
    "    \n",
    "    for i in range(no_hidden,-1,-1):\n",
    "        \n",
    "        gradients['dL/dW_layer{}'.format(i+1)] = np.zeros(Weights['layer_{}'.format(i+1)].shape)\n",
    "        for j in range(Weights['layer_{}'.format(i+1)].shape[0]):\n",
    "            for k in range(Weights['layer_{}'.format(i+1)].shape[1]):\n",
    "                gradients['dL/dW_layer{}'.format(i+1)][j][k] = np.sum((np.multiply(gradients['dL/dA_layer_{}'.format(i+1)][:,k], layers['layer_{}'.format(i)][:,j])))\n",
    "                \n",
    "        gradients['dL/dB_layer{}'.format(i+1)] = np.sum(gradients['dL/dA_layer_{}'.format(i+1)],axis=0)\n",
    "        if i != 0:\n",
    "            gradients['dL/dH_layer{}'.format(i)] = np.matmul(gradients['dL/dA_layer_{}'.format(i+1)],np.transpose(Weights['layer_{}'.format(i+1)]))\n",
    "            gradients['dL/dA_layer_{}'.format(i)] = gradient_fn[activation](layers['layer_wx_{}'.format(i)]) * gradients['dL/dH_layer{}'.format(i)]\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1707,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(gradients, Weights, Bias, learning_rate,no_hidden):\n",
    "    for i in range(no_hidden+1,0,-1):\n",
    "        Weights['layer_{}'.format(i)] = Weights['layer_{}'.format(i)] - (learning_rate * gradients['dL/dW_layer{}'.format(i)])\n",
    "        Bias['layer_{}'.format(i)] = Bias['layer_{}'.format(i)] - (learning_rate * gradients['dL/dB_layer{}'.format(i)])\n",
    "        \n",
    "    return Weights, Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, hidden_units, Weights, Bias, activation = 'sigmoid', epochs = 10000, learning_rate = 0.01):\n",
    "    error = []\n",
    "    y_act = output_label_hot_encode(y)\n",
    "    \n",
    "    no_hidden = len(hidden_units)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        layers, y_hat = forward_propagation(X, y, Weights, Bias, no_hidden, activation)\n",
    "        gradients = backward_propagation(layers, y_act, y_hat, Weights, Bias, no_hidden, activation)\n",
    "        Weights, Bias = update_params(gradients, Weights, Bias, learning_rate, no_hidden)\n",
    "        ce_error = cross_entropy_error(y_act, y_hat)\n",
    "        if i%10 == 0: error.append(ce_error)\n",
    "        if ce_error < 10:\n",
    "            break\n",
    "    return error, y_act, y_hat, Weights, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1747,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [2]\n",
    "Weights, Bias = weight_init(X, y, hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1778,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "hidden_units = [3,3]\n",
    "Weights, Bias = weight_init(X, y, hidden_units)\n",
    "error, y_act, y_hat, Weight_new, iters = train(X, y, hidden_units, Weights, Bias, activation = 'sigmoid', epochs = 10000, learning_rate = 0.1)\n",
    "print(iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a275bddc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(error)\n",
    "plt.ylabel('Errors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0365575194545529"
      ]
     },
     "execution_count": 1671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5]])"
      ]
     },
     "execution_count": 1744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(y_hat,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
