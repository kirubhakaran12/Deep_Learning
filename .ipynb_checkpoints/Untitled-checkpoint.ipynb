{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "size = 100\n",
    "x11 = np.random.uniform(low=0.0,high=1.0,size=size)\n",
    "x12 = np.random.uniform(low=2.0,high=8.0,size=size)\n",
    "x13 = np.random.uniform(low=6.0,high=8.0,size=size)\n",
    "\n",
    "x21 = np.random.uniform(low=10.0,high=11.0,size=size)\n",
    "x22 = np.random.uniform(low=12.0,high=18.0,size=size)\n",
    "x23 = np.random.uniform(low=16.0,high=18.0,size=size)\n",
    "\n",
    "x31 = np.random.uniform(low=20.0,high=21.0,size=size)\n",
    "x32 = np.random.uniform(low=22.0,high=28.0,size=size)\n",
    "x33 = np.random.uniform(low=26.0,high=28.0,size=size)\n",
    "\n",
    "y1 = np.transpose(np.zeros(100))\n",
    "y2 = np.transpose(np.ones(100))\n",
    "y3 = np.transpose(np.ones(100) * 2)\n",
    "\n",
    "X1 = np.transpose(np.array([x11, x12, x13]))\n",
    "X2 = np.transpose(np.array([x21, x22, x23]))\n",
    "X3 = np.transpose(np.array([x31, x32, x33]))\n",
    "X = np.vstack((X1, X2, X3))\n",
    "\n",
    "y = np.hstack((y1, y2, y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1': array([[ 0.82716226,  0.12701214,  0.83785176],\n",
       "        [ 0.6649236 ,  0.22273736,  0.32733791],\n",
       "        [ 0.91828482,  0.94860678,  0.73148042],\n",
       "        [ 0.68900687,  0.75888815,  0.06113174]]),\n",
       " 'layer_2': array([[ 0.92527163,  0.06146571,  0.98512263,  0.42843846],\n",
       "        [ 0.30721224,  0.14117636,  0.21565687,  0.40362563],\n",
       "        [ 0.56121971,  0.02327633,  0.21513778,  0.36573037]]),\n",
       " 'layer_3': array([[ 0.62249111,  0.48061596,  0.70146295],\n",
       "        [ 0.19419812,  0.20816187,  0.79600652],\n",
       "        [ 0.07197037,  0.16703081,  0.29774799]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = [4,3]\n",
    "no_hidden = len(hidden_units)\n",
    "\n",
    "def weight_init(X, y, hidden_units):\n",
    "    \n",
    "    Weights = {}\n",
    "    Bias = {}\n",
    "    no_features = X.shape[1]\n",
    "    for n, units in enumerate(hidden_units):\n",
    "        Weights['layer_{}'.format(n+1)] = np.random.rand(no_features,units) \n",
    "        Bias['layer_{}'.format(n+1)] = np.random.rand(units) \n",
    "        no_features = units\n",
    "    \n",
    "    labels = len(np.unique(y))\n",
    "    Weights['layer_{}'.format(no_hidden+1)] = np.random.rand(no_features, labels)\n",
    "    Bias['layer_{}'.format(no_hidden+1)] = np.random.rand(labels)\n",
    "    \n",
    "    return Weights, Bias\n",
    "\n",
    "Weights, Bias = weight_init(X, y, hidden_units)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inp):\n",
    "    return (1/(1 + np.exp(inp)))\n",
    "\n",
    "def softmax(inp):\n",
    "    op_exp = np.exp(inp)\n",
    "    return op_exp/op_exp.sum(axis = 1)[:,None]\n",
    "\n",
    "def output_label_hot_encode(inp):\n",
    "    inp = inp.astype(int)\n",
    "    classes = np.unique(inp)\n",
    "    no_classes = classes.shape[0]\n",
    "    no_dim = inp.shape[0]\n",
    "    zero_arr = np.zeros((no_dim, no_classes))\n",
    "    zero_arr[np.arange(no_dim), inp] = 1.0\n",
    "    return zero_arr\n",
    "\n",
    "def gradient_sigmoid(inp):\n",
    "    return sigmoid(inp)*(1 - sigmoid(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,3) and (300,3) not aligned: 3 (dim 1) != 300 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-66373b87f861>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnl_act\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0ml_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnl_act\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-66373b87f861>\u001b[0m in \u001b[0;36mforward_prop\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnl_act\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0ml_act\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWeights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnl_act\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mBias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mnl_act\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_act\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0ml_act\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWeights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_hidden\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnl_act\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mBias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_hidden\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,3) and (300,3) not aligned: 3 (dim 1) != 300 (dim 0)"
     ]
    }
   ],
   "source": [
    "no_hidden = 2\n",
    "\n",
    "def forward_prop(X):\n",
    "    l_act = {}\n",
    "    nl_act = {}\n",
    "\n",
    "    nl_act['layer_{}'.format(0)] = X\n",
    "    for i in range(no_hidden):\n",
    "        l_act['layer_{}'.format(i+1)] = np.matmul(Weights['layer_{}'.format(i+1)],nl_act['layer_{}'.format(i)]) + Bias['layer_{}'.format(i+1)]\n",
    "        nl_act['layer_{}'.format(i+1)] = sigmoid(l_act['layer_{}'.format(i+1)])\n",
    "    l_act['layer_{}'.format(self.n_hidden+1)] = np.matmul(Weights['layer_{}'.format(no_hidden+1)],nl_act['layer_{}'.format(no_hidden)]) + Bias['layer_{}'.format(no_hidden+1)]\n",
    "    nl_act['layer_{}'.format(self.n_hidden+1)] = softmax(l_act['layer_{}'.format(no_hidden+1)])\n",
    "\n",
    "    return (l_act, nl_act)\n",
    "\n",
    "l_act, nl_act = forward_prop(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(self,l_act, nl_act,y_true):\n",
    "    k = self.output_dim\n",
    "    m = y_true.shape[1]\n",
    "    if self.loss == 'sq':\n",
    "        y_pred = nl_act['layer_{}'.format(self.n_hidden+1)]\n",
    "        inn_nl_prod = ((y_pred-y_true) * y_pred).reshape(1,k,-1)\n",
    "        tiled = np.repeat(np.identity(k), m, axis=1).reshape((k,k,-1)) - np.repeat(y_pred.reshape(k,1,-1), k, axis=1)\n",
    "        grad_y = np.sum(inn_nl_prod * tiled,axis=1)\n",
    "    else :\n",
    "        grad_y = -(y_true - nl_act['layer_{}'.format(self.n_hidden+1)])\n",
    "\n",
    "\n",
    "\n",
    "    grad_l_act = {}\n",
    "    grad_nl_act = {}\n",
    "    grads = {}\n",
    "\n",
    "    grad_l_act['layer_{}'.format(self.n_hidden+1)] = 1/m*grad_y\n",
    "    for i in range(self.n_hidden,-1,-1):\n",
    "        grads['W_{}'.format(i+1)] = np.matmul(grad_l_act['layer_{}'.format(i+1)], np.transpose(nl_act['layer_{}'.format(i)]))\n",
    "        grads['b_{}'.format(i+1)] = np.sum(grad_l_act['layer_{}'.format(i+1)],axis=1,keepdims=True)\n",
    "        grad_nl_act['layer_{}'.format(i)] = np.matmul(np.transpose(self.param['W_{}'.format(i+1)]),grad_l_act['layer_{}'.format(i+1)])\n",
    "        if (i==0):\n",
    "            break\n",
    "        grad_l_act['layer_{}'.format(i)] = eval('grad_' + self.activation)(l_act['layer_{}'.format(i)]) * grad_nl_act['layer_{}'.format(i)]\n",
    "    return grads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
