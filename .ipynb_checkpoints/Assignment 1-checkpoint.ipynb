{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "size = 100\n",
    "x11 = np.random.uniform(low=0.0,high=1.0,size=size)\n",
    "x12 = np.random.uniform(low=2.0,high=8.0,size=size)\n",
    "x13 = np.random.uniform(low=6.0,high=8.0,size=size)\n",
    "\n",
    "x21 = np.random.uniform(low=10.0,high=11.0,size=size)\n",
    "x22 = np.random.uniform(low=12.0,high=18.0,size=size)\n",
    "x23 = np.random.uniform(low=16.0,high=18.0,size=size)\n",
    "\n",
    "y1 = np.transpose(np.zeros(100))\n",
    "y2 = np.transpose(np.ones(100))\n",
    "\n",
    "X1 = np.transpose(np.array([x11, x12, x13]))\n",
    "X2 = np.transpose(np.array([x21, x22, x23]))\n",
    "X = np.vstack((X1, X2))\n",
    "\n",
    "Y = np.hstack((y1, y2))\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_neurons_layer = [6,5,4]\n",
    "\n",
    "def weight_init(input_matrix, no_neurons_layer):\n",
    "    \n",
    "    weight_matrix = list()\n",
    "    no_features = input_matrix.shape[1]\n",
    "    for neurons in no_neurons_layer:\n",
    "        weight_matrix.append(np.random.rand(no_features + 1,neurons))\n",
    "        no_features = neurons\n",
    "    \n",
    "    output_classes = len(np.unique(Y))\n",
    "    weight_matrix.append(np.random.rand(no_features + 1, output_classes) )\n",
    "    return weight_matrix\n",
    "\n",
    "weight_matrix = weight_init(X, no_neurons_layer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50930075,  0.49069925],\n",
       "       [ 0.50924033,  0.49075967],\n",
       "       [ 0.50917897,  0.49082103],\n",
       "       [ 0.50926157,  0.49073843],\n",
       "       [ 0.50922933,  0.49077067],\n",
       "       [ 0.5092292 ,  0.4907708 ],\n",
       "       [ 0.50926518,  0.49073482],\n",
       "       [ 0.50918131,  0.49081869],\n",
       "       [ 0.50920681,  0.49079319],\n",
       "       [ 0.50926911,  0.49073089],\n",
       "       [ 0.50920679,  0.49079321],\n",
       "       [ 0.50922399,  0.49077601],\n",
       "       [ 0.5092548 ,  0.4907452 ],\n",
       "       [ 0.50920841,  0.49079159],\n",
       "       [ 0.5094986 ,  0.4905014 ],\n",
       "       [ 0.50927484,  0.49072516],\n",
       "       [ 0.5092025 ,  0.4907975 ],\n",
       "       [ 0.5091659 ,  0.4908341 ],\n",
       "       [ 0.50926923,  0.49073077],\n",
       "       [ 0.50939043,  0.49060957],\n",
       "       [ 0.50936944,  0.49063056],\n",
       "       [ 0.50917463,  0.49082537],\n",
       "       [ 0.50923449,  0.49076551],\n",
       "       [ 0.50919903,  0.49080097],\n",
       "       [ 0.50932252,  0.49067748],\n",
       "       [ 0.50918715,  0.49081285],\n",
       "       [ 0.50919733,  0.49080267],\n",
       "       [ 0.50918742,  0.49081258],\n",
       "       [ 0.50920981,  0.49079019],\n",
       "       [ 0.50926484,  0.49073516],\n",
       "       [ 0.50933041,  0.49066959],\n",
       "       [ 0.50920789,  0.49079211],\n",
       "       [ 0.50919554,  0.49080446],\n",
       "       [ 0.50927559,  0.49072441],\n",
       "       [ 0.50918351,  0.49081649],\n",
       "       [ 0.50930026,  0.49069974],\n",
       "       [ 0.50926661,  0.49073339],\n",
       "       [ 0.50920921,  0.49079079],\n",
       "       [ 0.50925301,  0.49074699],\n",
       "       [ 0.50922135,  0.49077865],\n",
       "       [ 0.50928452,  0.49071548],\n",
       "       [ 0.50918131,  0.49081869],\n",
       "       [ 0.50921208,  0.49078792],\n",
       "       [ 0.5094072 ,  0.4905928 ],\n",
       "       [ 0.50924333,  0.49075667],\n",
       "       [ 0.50919937,  0.49080063],\n",
       "       [ 0.50923517,  0.49076483],\n",
       "       [ 0.50919367,  0.49080633],\n",
       "       [ 0.5092686 ,  0.4907314 ],\n",
       "       [ 0.5092762 ,  0.4907238 ],\n",
       "       [ 0.50917554,  0.49082446],\n",
       "       [ 0.50934443,  0.49065557],\n",
       "       [ 0.50917816,  0.49082184],\n",
       "       [ 0.50940196,  0.49059804],\n",
       "       [ 0.50921072,  0.49078928],\n",
       "       [ 0.50920067,  0.49079933],\n",
       "       [ 0.50921176,  0.49078824],\n",
       "       [ 0.50938385,  0.49061615],\n",
       "       [ 0.50934113,  0.49065887],\n",
       "       [ 0.50918031,  0.49081969],\n",
       "       [ 0.50928694,  0.49071306],\n",
       "       [ 0.50934086,  0.49065914],\n",
       "       [ 0.50935949,  0.49064051],\n",
       "       [ 0.50923635,  0.49076365],\n",
       "       [ 0.5092025 ,  0.4907975 ],\n",
       "       [ 0.50926076,  0.49073924],\n",
       "       [ 0.50929317,  0.49070683],\n",
       "       [ 0.50936959,  0.49063041],\n",
       "       [ 0.50919126,  0.49080874],\n",
       "       [ 0.5092686 ,  0.4907314 ],\n",
       "       [ 0.50927544,  0.49072456],\n",
       "       [ 0.50928988,  0.49071012],\n",
       "       [ 0.50926884,  0.49073116],\n",
       "       [ 0.50925014,  0.49074986],\n",
       "       [ 0.50934848,  0.49065152],\n",
       "       [ 0.50934721,  0.49065279],\n",
       "       [ 0.50920599,  0.49079401],\n",
       "       [ 0.50923846,  0.49076154],\n",
       "       [ 0.50921597,  0.49078403],\n",
       "       [ 0.50924495,  0.49075505],\n",
       "       [ 0.50925743,  0.49074257],\n",
       "       [ 0.5092172 ,  0.4907828 ],\n",
       "       [ 0.50921721,  0.49078279],\n",
       "       [ 0.50927725,  0.49072275],\n",
       "       [ 0.50935328,  0.49064672],\n",
       "       [ 0.50927082,  0.49072918],\n",
       "       [ 0.50921272,  0.49078728],\n",
       "       [ 0.50920512,  0.49079488],\n",
       "       [ 0.5092266 ,  0.4907734 ],\n",
       "       [ 0.50919745,  0.49080255],\n",
       "       [ 0.50922053,  0.49077947],\n",
       "       [ 0.50922   ,  0.49078   ],\n",
       "       [ 0.50929097,  0.49070903],\n",
       "       [ 0.50918269,  0.49081731],\n",
       "       [ 0.50930211,  0.49069789],\n",
       "       [ 0.50931468,  0.49068532],\n",
       "       [ 0.50924859,  0.49075141],\n",
       "       [ 0.50926587,  0.49073413],\n",
       "       [ 0.50932457,  0.49067543],\n",
       "       [ 0.50918893,  0.49081107],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909244,  0.49090756],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909244,  0.49090756],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909243,  0.49090757],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909241,  0.49090759],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758],\n",
       "       [ 0.50909242,  0.49090758]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_bias(inp):\n",
    "    return np.c_[inp,np.ones(inp.shape[0])]\n",
    "\n",
    "def mat_multiply(mat1, mat2):\n",
    "    return np.matmul(mat1, mat2)\n",
    "\n",
    "def sigmoid(inp):\n",
    "    return (1/(1 + np.exp(inp)))\n",
    "\n",
    "def softmax(inp):\n",
    "    op_exp = np.exp(inp)\n",
    "    return op_exp/op_exp.sum(axis = 1)[:,None]\n",
    "\n",
    "def output_class_encode(inp):\n",
    "    inp = inp.astype(int)\n",
    "    classes = np.unique(inp)\n",
    "    no_classes = classes.shape[0]\n",
    "    no_dim = inp.shape[0]\n",
    "    zero_arr = np.zeros((no_dim, no_classes))\n",
    "    zero_arr[np.arange(no_dim), inp] = 1.0\n",
    "    return zero_arr\n",
    "\n",
    "def least_squares_error(actual, predicted):\n",
    "    return\n",
    "\n",
    "def feed_forward(input_matrix, ouptut_class, no_neurons_layer):\n",
    "    layers = [None] * (len(no_neurons_layer) + 2) #2 - one for input and one for output and the rest are hidden layers\n",
    "    layers[0] = input_matrix #input layer\n",
    "\n",
    "    for layer in range(len(no_neurons_layer) + 1):\n",
    "        layers[layer + 1] = sigmoid(mat_multiply(add_bias(layers[layer]), weight_matrix[layer]))\n",
    "    return softmax(layers[len(no_neurons_layer)+1])\n",
    "\n",
    "feed_forward(X, Y, no_neurons_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-235-ffe9ba0b0bbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput_class_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-234-827e8c9a3055>\u001b[0m in \u001b[0;36moutput_class_encode\u001b[1;34m(inp)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mno_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mzero_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mzero_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mzero_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "output_class_encode(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[np.arange(200), inp] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_dim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
